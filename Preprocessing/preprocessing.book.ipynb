{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "governmental-footage",
   "metadata": {},
   "source": [
    "# 前処理大全"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "supported-genre",
   "metadata": {},
   "source": [
    "# 第一章 前処理とは"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "extra-tanzania",
   "metadata": {},
   "source": [
    "### データ分析の３つの前処理\n",
    "- 表やグラフ作成用の前処理\n",
    "- 教師なし学習へ入力するための前処理\n",
    "- 教師あり学習へ入力するための前処理"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "figured-senate",
   "metadata": {},
   "source": [
    "### 前処理の流れ  \n",
    "#### 1 データ構造を対象とした処理:大きなデータを扱うので、SQLが有利。  \n",
    "- 対象データの抽出や結合、集約など  \n",
    " \n",
    "#### 2 データ内容を対象とした処理：値の修正などのため、python有利。  \n",
    "- データ内容の変更や、欠損値の補完など  \n",
    "→ 集計やグラフの描写に使用  \n",
    "- 機械学習モデルのために変換  \n",
    "→ 教師なし学習用データ  \n",
    "    \n",
    "#### 3 データ構造を対象とした処理:機械学習用のライブラリの多いpythonを使用。  \n",
    "- 学習、テストデータの分割  \n",
    "→ 教師あり学習用データ  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "usual-triangle",
   "metadata": {},
   "source": [
    "## 第二章 抽出\n",
    "データサイズを小さくするメリットは多いので、必要なデータのみを抽出するようにする。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "agricultural-operations",
   "metadata": {},
   "source": [
    "### 注意事項\n",
    "- iloc、ixなど値で指定する方法は不推奨、locや配列に文字列を使用する事を推奨。\n",
    "- indexが無い場合、条件指定時に全探索する事になる。indexがあれば、必要範囲の指定となるので処理速度が向上。\n",
    "- 条件指定抽出は、query関数が一番視認性が良いので推奨。\n",
    "- データ量を指定の数に減らせるsample関数は重要であるが、指定する項目の選択によってはデータ割合に支障をきたすので注意が必要。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "structural-dallas",
   "metadata": {},
   "source": [
    "# 第三章 集約"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "marked-minister",
   "metadata": {},
   "source": [
    "集約方法は大きく分けると２つの方法がある  \n",
    "- groupby    : 条件表現が豊富、但し記述量が多い。\n",
    "- Window関数  : SQLが簡単に書けてオススメ！！ グループ毎に並び替えて順位づけする事に長けている。\n",
    "\n",
    "**注意事項**  \n",
    "- 集約処理とwindow関数の実行を同時にはできない。（SQLはできる)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "historical-nevada",
   "metadata": {},
   "source": [
    "### aggが便利\n",
    "- agg({\"指定先1\":処理内容1,\"指定先2\":処理内容})と記述するだけで、複数の処理を行ってくれる。 \n",
    "- １つの処理の時には、記述量が増えるので使わない。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "front-damage",
   "metadata": {},
   "source": [
    "# 第四章 結合"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "accessory-fighter",
   "metadata": {},
   "source": [
    "### マスターテーブルとレコードテーブル\n",
    "- マスターテーブルは、顧客の情報などの共通情報を保管しており、顧客IDを持っている。\n",
    "- レコードテーブルは、商品情報や店舗情報など様々な種類がある。\n",
    "\n",
    "レコードテーブルにも顧客IDを所持するものもあり、マスターテーブルと結合することで、顧客情報の紐付けができる。\n",
    "\n",
    "### 注意事項  \n",
    "結合前になるべく不要なもの除くために抽出しておく。  \n",
    "\n",
    "### 過去データの取扱　　\n",
    "- 結合対象の期間を絞る。\n",
    "- 結合した過去データに集約関数を利用する。 window関数が最適、但しpythonは実装されてないのでrolling関数を利用する。  \n",
    "  rolling: https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.rolling.html"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adopted-walter",
   "metadata": {},
   "source": [
    "# 第五章 分割  \n",
    "SQLでの作業は全く効率的でないためしない事。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "material-cabinet",
   "metadata": {},
   "source": [
    "## 時系列データにおける処理\n",
    "- 単純な交差検証は有効ではない。未来のデータが混じっている可能性がある。\n",
    "- 上記の対策として、期間をスライドさせたり、期間を追加していく検証方法が有効。  \n",
    "- 期間を追加して行く場合は、追加する時期によりデータ量が変わってくるので、データ量の増加に伴う精度の関係も把握する必要がある。\n",
    "\n",
    "**注意事項**\n",
    "- pythonには時系列データを簡単に扱えるライブラリは無い。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "different-affect",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "df = pd.read_csv(\"awesomebook/data/month_mst.csv\")\n",
    "df[\"year_month\"] = df[\"year_num\"].astype(str) + \"-\" + df[\"month_num\"].astype(str)\n",
    "df[\"year_month\"] = df[\"year_month\"].sort_values(ascending=True)\n",
    "df.sort_values(by=\"year_month\")\n",
    "\n",
    "\n",
    "train_window_start = 1\n",
    "train_window_end   = 24\n",
    "horizon = 12\n",
    "skip    = 12\n",
    "\n",
    "while True:\n",
    "    test_window_end = train_window_end + horizon\n",
    "    train = df[train_window_start:train_window_end]\n",
    "    test  = df[(train_window_end + 1):test_window_end]\n",
    "    if test_window_end >= len(df.index):\n",
    "        break\n",
    "\n",
    "    train_window_start += skip\n",
    "    train_window_end += skip"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "greenhouse-george",
   "metadata": {},
   "source": [
    "# 第六章 生成"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "retained-nicaragua",
   "metadata": {},
   "source": [
    "## 不均等データの調整\n",
    "\n",
    "障害でないデータに対して、障害データが極端に少ないケースを不均等と言う。\n",
    "不均等なデータは機械学習の予測精度が下がる要因となる可能性が多い。\n",
    "\n",
    "## 不均等なデータへの対策\n",
    "- 機械学習のモデル制作時に重みを与える。\n",
    "- データを操作して不均等な状態を解除する。  \n",
    "  -少ないデータを増やす : オーバーサンプリング  \n",
    "  -多いデータを減らす   : アンダーサンプリング  \n",
    "  -この両方を行う方法\n",
    "  \n",
    "## アンダーサンプリング\n",
    "多い方のデータを減らすだけなので、簡単に実装出来ます。。  \n",
    "但し、データを減らす事は勿体無いので、基本的にはオーバーサンプリングを行います。  \n",
    "オーバーサンプリングで過学習を起こしそうな場合に、両方行うようにする事が望ましい。\n",
    "\n",
    "## オーバーサンプリング  \n",
    "データを増やす時に使う、増やす手法としてSMOTEが使いやすい。  \n",
    "SMOTEは、障害データとその選択候補となるデータの中間に新たなデータを作る手法。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "loaded-general",
   "metadata": {},
   "outputs": [],
   "source": [
    "from "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
